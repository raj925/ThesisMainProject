---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::pdf_document2:
    template: templates/template.tex
  bookdown::html_document2: default
  bookdown::word_document2: default
documentclass: book
#bibliography: [bibliography/references.bib, bibliography/additional-references.bib]
---

```{r, echo=FALSE}

# Colour coding for figures
confidenceColour <- "#03c200"
difficultyColour <- "#bf00c2"
infoSeekingColour <- "#ca0600"
differentialColour <- "skyblue"
likelihoodColour <- "orange"
accuracyColour <- "black"
resolutionColour <- "yellow"
```

# Study 2 - Investigating Confidence and Information Seeking in Non-Medical Decisions {.unnumbered}

```{=tex}
\adjustmtc
\markboth{Introduction}{}
```
<!-- For PDF output, include these two LaTeX commands after unnumbered chapter headings, otherwise the mini table of contents and the running header will show the previous chapter -->

In our follow-up study, we wanted to look at a similar style of decision making to Study 1 but in a non-medical context. We wanted to use a task that did not require the same level of specialised domain knowledge that medicine requires to see if similar findings hold. The structure of this task is the same as the medical task of Study 1, in that there are 3 stages of information seeking with 29 pieces of information in total that could be requested, interspersed with reporting of differentials and confidence. The aim of this task, referred henceforth as the Country Task, is for participants to identify a country based on a series of information that they can request about it. None of the information they can request is able to indicate the country on its own (e.g. participants are not told the capital city of the country). Hence, participants have to request and consolidate a decent amount of information in order to determine the country. The aim of this task is to observe whether patterns of information seeking and confidence extend to other domains outside of the specialised field of medicine. 

## Methods {.unnumbered}

### Participants {.unnumbered}

The experiment was implemented using the same JSPsych code base as used in Study 1. Participants were recruited from the global general population using the online recruitment platform Prolific. Participant age ranged between 20-66 (M = 32.11, SD = 10.32). In total, 36 participants were recruited for the pilot of the study. Inclusion criteria for this study stipulated that participants were aged between 18 and 70, were fluent in English and had normal-to-corrected vision. Participants were recruited between the 14th and 19th of October 2022. 

We had used R’s pwr.anova.test function to conduct a power analysis for a balanced one-way analysis of variance (ANOVA). We intended to compare high and low groups of geographic knowledge (median split by their score on the geography quiz). Hence, our power analysis was computed for two groups to detect an effect size f of 0.4 at 95% power and an alpha value of 0.05. This produced a sample size of 41.59 per group, meaning a total of around 84 across both groups. As a result, for our main study, we recruited 87 participants with ages from 20 to 66 (M = 33.87, SD = 11.79). Of these participants, 35 were female (40.2%). Inclusion criteria for this study stipulated that participants were aged between 18 and 70, were fluent in English and had normal-to-corrected vision. Participants were recruited between the 19th and 30th of January 2023.

### Procedure {.unnumbered}

For this study, participants have to guess a country that is being described by a set of information. This information includes ‘the number of colours on the country’s flag’, ‘the country’s area’, ‘native animals’ and ‘average temperature’. For any numerical values, such as area and population, these are provided as global ranks (e.g. a country might be the 13th largest in the world). This is because absolute values lack any real context on their own (e.g. an area of 30,000km2 is unlikely to be helpful information). The information is split into three stages: Geography, Economy & Politics and People & Culture. Across all three stages, there are 29 pieces of information in total that can be requested (the same amount as in the medical task of study 1). At the start of each trial, participants are told the continent in which the country presides. Participants are then free to gather as much information as they want within each stage. Once they are finished gathering information, they then report a list of all possible countries they are considering based on the current set of information they have seen. With each country, participants report how likely that country is on a scale from 1 to 10. Once this is done, participants rate their confidence that they have the current country included in their list on a scale from 0 to 100. In subsequent stages, the participants’ list from the previous stage is shown for them to update. This includes the ability to remove countries from the list if they are no longer under consideration. 

This study involved 6 trials, each with a true underlying country. These countries were: South Korea, Mongolia, Colombia, Switzerland, Greece and Botswana. The order in which the countries were presented was randomised for each participant. We also included a practice country (Thailand) to familiarise the participants with the experimental procedure and the interface. When coding responses for accuracy, any spelling mistakes were accepted as correct answers (e.g. ‘Columbia’ was accepted as a correct answer for the Colombia trial). We also accepted ‘Korea’ as a correct answer for the South Korea trial, as well as ‘Mongol’ for the Mongolia trial. 

Before beginning the main experiment, participants were asked to complete a geography quiz that featured multiple choice questions. This allowed us to have a measure of expertise (via geographic knowledge) to look at confidence and information seeking against. A separate data collection was run to validate and create this quiz. An initial set of 40 multiple choice questions was first created, each with four possible answers (with only one being the correct answer). This included questions such as “What colour is the star on the flag of Ghana?”, “Which volcano lies on the east coast of Sicily?’ and “Which of the following countries is landlocked?” The aim was to use questions with clear answers whilst also tapping into a similar bed of knowledge that is used to complete the main task. To determine the validity of these questions, we collected and included responses from 99 participants to all 40 questions presented in a randomised order and with randomised order of multiple choices. This quiz was implemented using Qualtrics and participants were recruited using Prolific. Inclusion criteria for this study were that participants were aged 18 or over, were fluent in English and had normal-to-corrected vision. Each question was timed, such that participants were given only 10 seconds to read and answer the question with one of the four possible options. If the participant failed to provide the answer in the allotted time, they would be timed out, no response would be recorded for that question and the quiz would move onto the next question. This time limit was to ensure that participants did not spend too long thinking about their answer (instead answering based on intuition) and also to reduce the participant’s ability to search the answer to questions online. Amongst the 40 questions were two attention checks (again, randomly placed within the order of questions). One of these said the following: “it is important you pay attention to this study. Please answer Asia for this question” (with the other options between Europe, South America and Africa). The other attention check question said the following “it is important you pay attention to this study. Please do not provide any answer to this question and let the timer run out”. For this second attention check, participants would pass the attention check if they did not click on any of the multiple choices provided (all of which were the same continents as the other attention check).  If the participant failed either of these attention checks, their participation was immediately ceased and their data was not used. 

With the responses to questions on the geography quiz where participants passed the attention checks, we scored each answer based on whether it was the correct answer or not. Based on this data, we can compute the total score for each participant. Out of a possible 40, participants scored between 11 and 34 (M = 21.34, SD = 4.96). We then computed discrimination index for individual questions such that we determine which questions are able to differentiate participants by their overall performance. We sought only to use questions that had a discrimination index of 0.2 or higher . Out of the 40 questions, 17 questions met this criterion. Hence, our geography quiz in the main study were these 17 questions, using the same randomisation and attention checks as in the initial data collection for the quiz. This final set included questions such as “The Angkor Wat is the largest religious monument in the world located in which country?”, “What is the capital of Brazil?” and “What is the name of the microstate located between Spain and France?” Each participant included hence achieved a score based on the number of the correct responses in the quiz, with the maximum value being 17. Participants in the main study scored between YA and BLA (M =, SD =).

Recording performance on this geography quiz allows us to obtain a measure of the participants’ latent geographic knowledge. We can then investigate whether task knowledge affects overall performance, metacognitive performance and information seeking patterns. 

## Results {.unnumbered}

Firstly, we again looked at our key dependent variables changed over the course of the three stages. We found similar patterns to the results from Study 1. When conducting a Welch's ANOVA, we found that participants increased their confidence with the stage on average (F(1.68,145.38) = 21.39, p < .001). We also found that accuracy (by the likelihood of the correct differential if it was present in the participant’s list,) increased on average (F(1.40,121.62) = 54.27, p <.001). When measuring the relationship between the two directly, we found a significant correlation between the confidence provided at the final stage and likelihood score at the final stage (r(86) = .55, p < .001). This indicates overall that participants were well calibrated in their confidence judgements when compared with their objective performance. We also find a correlation between geographic knowledge and likelihood score (r(86) = .33, p < .001). In other words, participants with more geographic knowledge before the task performed better on the task. In addition, we found support for a positive association between the amount of information sought across a case and the change in confidence (r(86) = .22, p = .04). We also find evidence for a significant correlation between geographic knowledge and likelihood score (r(86) =.33, p < .001). Whilst there is a large degree of noise at zero (whereby participants who are incorrect on all six trials display a wide range of geographic knowledge), this points to a general trend where having higher geographic knowledge tends to result in better performance on the task. This at least suggests that the measure derived from the geography quiz displays construct validity with regards to the task itself.

We split participants into groups by their score on the geography quiz in two different ways: by using a median split (to create two groups of HIgh and Low knowledge participants) and by quantiles (to create four groups of participants). We also split cases into high and low difficulty by their objective accuracy across participants, with the high difficulty cases being Switzerland, Greece and Botswana. 

A hypothesis that we had before the study, which was informed by previous work, is that one marker of expertise is a sensitivity to difficulty that is expressed via subjective confidence. To investigate this, we median split participants by their geographic knowledge and then 2x2 Mixed ANOVA was performed with confidence change (the difference between final and initial confidence) as a dependent variable. We found support for a main effect of case difficulty on confidence change (F(1,86) = 6.14, p = .01) but did not find support for a main effect of knowledge (F(1,86) = 1.76, p = .19). However, we find support for an interaction effect (F(1,86) = 4.81, p = .03). The presence of an interaction effect suggests a sensitivity to difficulty that is expressed via confidence which comes with geographic knowledge, whereby participants with lower knowledge express similar confidence for easy and hard trials.

We also sought to characterise information seeking patterns as a function of geographic knowledge. To do this, we first split participants into quartiles based on their geographic quiz score. Within each quartile, we then compute the variance in Euclidean distances between all trials’ information seeking vectors within each quartile. Similar to the medical task, each trial contains 29 pieces of information that can be requested, so each vector is of length 29 where each value is a 1 if that information was requested and 0 if that information was not requested. A lower variance in Euclidean distances within a quartile indicates that participants within that quartile sought information in a more homogenous way (i.e. more similarly to one another). When looking at variance values, we find that a quadratic relationship such that participants with the highest and lowest geographic are more homogenous in their information seeking patterns. When looking at information seeking variance by country/trial, we do not find a consistent pattern for how trial difficulty (where countries are labelled as easy or hard by a median split on objective accuracy across participants) affects information seeking variance. 

To investigate how knowledge affects information seeking in a systematic manner, we trained a binary classifier using a neural network algorithm to detect whether participants belong to the high or low geographic knowledge group. The predictors for our classifiers were binary variables on each trial for whether a particular piece of information was requested or not (29 predictors in total). We use all trials across participants for training and testing the classifier, resulting in a total of 528 trials (88 participants performing 6 trials each). To ensure that our classifiers are not overfitted to the data, we split trials into a training and testing set with 80% of trials used for training. We iterate this process of splitting the data and then calculate the average ROC AUC across 100 iterations. In each iteration, after splitting the data into training and testing sets, we again iteratively split the training set into sub-training and sub-test sets to maximise AUC by finding the optimal values for the number of hidden layers and weight decay, which are free tuning parameters in our algorithm. For hidden layers, we iterate between 1 to 10 hidden layers, with the average AUC computed across 5 iterations for each possible value for the number of hidden layers (at a weight decay of 0). For weight decay, we iterate through values of between 0.001 and 0.03 (in increments of 0.001), with the average AUC computed across 5 iterations for each possible value of weight decay (at a hidden layer of the optimal value computed in the previous step). Once the optimal values for hidden layers and weight decay are computed, these parameters are applied to classify the original test trials and an ROC is generated. The AUC of this ROC is recorded on each entire iteration and averaged across the 100 iterations. We find an average AUC of 0.940, which indicates that the classifier has high accuracy in differentiating between low and high geographic knowledge participants based on their information seeking patterns. In other words, geography expertise seems to broadly affect how participants seek information on the task.

To further investigate this finding, we then treat geographic knowledge score as an ordinal variable (taking integer values ranging from 0 to 17) and investigate whether information seeking predicts this score using Principal Components regression with Leave One Out validation. The aim of this process is, given our binary predictor variables, to find a number of linear combinations smaller than the number of total predictors and then use least squares to fit a linear regression model using the principal components as predictors. When computing the number of principal components to use, we visualise the cumulative RMSE across the number of components used. We find multiple ‘elbows’ in the curve, with the change in RMSE levelling off at 11 components. When testing on the same dataset using a PCR model with 11 components, we find a test RMSE of 4.60 when predicting the geographic knowledge score. Bearing in mind that this score has a range 0-17, this RMSE constitutes 27.08% of the entire range of geographic knowledge scores. This indicates a large degree of error in predicting score, suggesting that information seeking patterns are not precisely predictive of geographic knowledge. 

We can also investigate how similar information seeking is across case by knowledge level through the training binary classifiers on the information seeing behaviour on one set of country trials (e.g. South Korea) and test the classifier on another set of country trials (e.g. Mongolia). This was done using the same neural networks method explained above, using the same procedure to derive the optimal parameter values for hidden layers and decay. When training and testing classifiers on every combination of country trials (excluding training and testing on the same country trials), we only find that two classifiers out of thirty produce an AUC of > 0.7 (values 0.74 and 0.71). This indicates that information seeking behaviour is not highly consistent within low and high knowledge participants across trials. 


## Discussion {.unnumbered}
 
It is worth comparing the country task to the diagnosis task to assess the extent to which they are analogous. Structurally, the tasks were designed to be close to each other as possible. In this respect, the number of stages and the amount of information is the same across both tasks. The tasks also both use the same code and interface, as well as the same experimental flow. There are a couple of changes to note from the procedure of Study 1 aside from the obvious change in visual stimuli shown. Firstly, participants only reported a likelihood rating for each differential, whereas medical students had to report both likelihood and severity ratings for each diagnostic differential. We also found from piloting our study that we had to incentivise information gathering. When piloting our medical task from Study 1, we found that medical students had a natural inclination to click on most if not all information given there was no cost to doing so. Hence, we implemented a time delay of 3 seconds in order to prompt participants to consider the information they chose to gather more carefully. When piloting the country task, we found the opposite issue: participants tended not to request information due to this delay. Hence, we shortened the delay between clicking on an information request and receiving the information from 3 seconds to 0.5 seconds. We also removed the ‘Ready to Treat’ button from the confidence screen, as this was not relevant for this task.

There are notable differences between the tasks. For the medical task, the available pieces of information are all relatively useful such that a participant could realistically request all the information available to make a diagnosis if time constraints were not present. However, for the country task, one could intuit some information to be more useful than others. This is of course subjective on our part in terms of how useful information is, but it is clear that some information is more uniquely discriminant than others. For example, knowing the number of colours in a country’s flag is more likely to be useful than knowing the proportion of a country that is covered in forest. 

