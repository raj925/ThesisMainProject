---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::pdf_document2:
    template: templates/template.tex
  bookdown::html_document2: default
  bookdown::word_document2: default
documentclass: book
#bibliography: [bibliography/references.bib, bibliography/additional-references.bib]
---

# Introduction {.unnumbered}

```{=tex}
\adjustmtc
\markboth{Introduction}{}
```
<!-- For PDF output, include these two LaTeX commands after unnumbered chapter headings, otherwise the mini table of contents and the running header will show the previous chapter -->

Imagine a group of doctors within an intensive care unit (or critical care unit, depending on the parlance used in different geographic regions). They are engaged in a collective discussion about a particular patient. The patient has presented with a series of symptoms, including dizziness, breathing difficulties and eventual chest pain. She has been placed under continuous monitoring of her ‘vital signs’. These are considered to be some of the most important metrics for tracking the human body’s essential capabilities and can include heart rate, body temperature, blood pressure, blood oxygen saturation and respiration rate. In the case of our aforementioned patient, she has been recording a slow decrease in blood pressure and blood oxygen saturation. The doctors have to decide what is the most likely cause of this patient’s symptoms and vital signs. It is possible that the patient is suffering from a pulmonary edema, whereby fluid is collected in the air sacs of the lungs, causing severe and sometimes fatal congestion. The symptoms could also be suggestive of a tension pneumothorax, which is when a lung collapses. Alternatively, the cause could be that the patient is suffering an anaphylactic shock, which is a severe allergic reaction that can in itself cause fluid to enter the lungs and constrict an individual’s airways. The doctors must integrate the information they have so far, align their mental models of the patient and decide the following:

1. Do they have enough information to make a determination of the patient’s condition? 
2. If not, what extra information do they need? Are there further tests that need to be performed?
3. As per their most likely diagnosis, what actions should they start taking to treat the patient?

One of the difficulties within this scenario here is that symptoms may be indicative of multiple underlying conditions. This example is illustrative of why many medical decisions are ‘ill-structured’ problems: they present several possible methods for reaching a solution and even produce disagreements over a desirable starting hypothesis and end state (Jonassen, 1997). Individuals involved in clinical decision making have to frequently contend with an uncertain decision making environment, as well as time pressure and personal stresses (Orasanu & Connolly, 1993). Alignment of mental models for the medical staff involved in a patient case is therefore critical that they can formulate very different understandings of a patient’s condition and how it would be best to proceed. Medical staff have to align their thoughts in order to align their actions and function as a cohesive team. This is despite the fact that they often have to operate under uncertainty. While clinicians can continue to gather information in order to reduce their uncertainty, there is a further constraint enforced upon them: time. They frequently have to perform their job while observing the deterioration of a patient’s health. This means that clinicians have to choose carefully when to commit to a particular working diagnosis in order to guide their future actions for treating the patient, even when they cannot freely choose the point of commitment. 

Part of what makes medical decision making particularly challenging is the lack of clear feedback, as there might be in other task contexts. When making a particular diagnosis for a patient, clinicians likely do not receive a lot of feedback about the correctness of their diagnosis. Some may view diagnostic tests (eg blood tests) as a form of feedback: doctors use these test results to either reinforce or re-evaluate their prior beliefs. However, tests are not objective markers of feedback, as they can differing levels of sensitivity and specificity rates, leading to false positives, false negatives or even inconclusive results. The results can be used by clinicians to guide their future beliefs and actions, but they are primarily a form of information gathering that can be used to confirm existing hypotheses or eliminate differential hypotheses. Feedback may only be brought up to the clinician based on how a patient’s status changes. Generally, doctors gather information through tests, patient documentation and other means to generate a model of the patient’s condition, through which they can surmise a hypothesis for what could be the underlying condition of a patient. Based on this hypothesis, the doctor can then prescribe the most suitable treatment. Hence, a patient’s reaction to treatment, and their rate of recovery, can be seen as a form of feedback on the doctor’s initial model of the patient. This in itself is an imperfect form of feedback, as patients can deteriorate or improve due to circumstances outside of the doctor’s control or awareness. This makes confidence an interesting notion to study. Confidence is viewed within cognitive psychology as one’s subjective probability of their own decisions being correct. In the absence of feedback, confidence can be used as a marker of how likely someone is to be correct. In the case of medicine, a lack of clearly communicable feedback can cause clinicians to proceed as if they have received positive feedback. This means that they do not adequately update their internal model of the patient and hence they increase their confidence inappropriately (Jaspan et al, 2022). In most psychology experiments, the feedback provided to participants is the objective correctness of a decision but in the case of medicine, feedback is more difficult to define given the lack of objective markers of correctness. As we shall discuss, this has implications on the study of confidence calibration. That is, how confident an individual is relative to their true accuracy. 

Medicine also has an interesting wrinkle of real-world decision making that makes it different to classic psychology experiments. In a task such as the Information Sampling Task (IST) (reference), participants gather information by revealing squares on a grid that can be one of two colours, with one colour being the majority colour on the grid. Participants reveal colours until they are ready to decide, at which point they report which colour they think is the more prevalent colour. Here, there is a clear delineation between information gathering and decision making. In the healthcare sector, a clinician may decide to prescribe a certain course of treatment to the patient in order to start treating their condition or lessening the symptoms. However, this in itself is a form of information gathering, as the patient’s reaction to treatment can itself yield informative information about their underlying condition. This can force clinicians to rethink their model of the patient. Hence, information gathering and decision making is more interleaved in real-world contexts such as healthcare.  

Clinicians have to make challenging decisions as part of their occupation, such as administration of medication, allocation of hospital space and delegation of responsibilities to colleagues. However, one such group of decisions is diagnosis, which is notable to study for a number of reasons. Firstly, it allows for an extension of previous research on information gathering and confidence within psychology. This allows for past findings to be applied within an ecologically valid, real-world setting. Secondly, diagnosis is an important task that has a large impact on a patient’s road to recovery. Ensuring that a patient has positive outcomes in their treatment is in large part contingent on an accurate diagnosis of their conditions being made by healthcare professionals. 

Firstly, it is worth painting a picture of the wider context of diagnostic errors. Looking into errors more broadly allows healthcare systems to learn from mistakes to improve technical and safety processes for future patients. Understanding the common sources of medical errors and adverse events can be extremely valuable for improving healthcare in the future. For example, Cohen et al (2021) analysed surgical adverse events in California to find that the majority of events were caused by the retention of foreign objects from surgery. However, there is also work looking at errors in diagnosis, which ties into questions of how humans gather information and formulate their confidence that are studied through the lens of cognitive psychology.

## Diagnostic Errors {.unnumbered}

Diagnostic discrepancies are where an initial diagnosis is different to a diagnosis made for a patient upon their discharge from hospital. In other words, this would indicate that the initial diagnosis was incorrect. A report from the US Institute of Medicine (McGlynn, McDonald & Cassel, 2015) concluded that many people will experience a diagnostic error within their lifetime. The Harvard Medical Practice Study found that diagnostic errors were responsible for 17% of adverse events (Leape et al, 1991). The Canadian Adverse Events Study found this value to be 10.5% (Baker, Norton & Flintoft, 2004) whilst a study in New Zealand found this value to be 8% (Davis et al, 2003).  When looking at records of new diagnoses for spinal epidural abscess in the US Department of Veteran Affairs, Bhise et al (2017) found that 55.5% of patients experienced diagnostic error. The Quality in Australian Health Care Study found that 20% of adverse events were due to delayed diagnosis (Wilson et al, 1999). Around 32% of clinical errors have been found to be caused by clinician assessment, particularly the clinician’s failure to weigh up competing diagnoses (Schiff et al, 2009). Diagnostic errors have been found to be have downstream consequences, leading to longer hospital stays and even increased patient mortality (Hautz et al, 2019). Even when using the most conservative estimates, this illustrates the large scale of the diagnostic error when extrapolated to the population of patients. Studies have even investigated downstream consequences of diagnostic errors, with unnecessary treatments (or ‘overtreatment’) estimated to cost the US healthcare system between 158 and 226 billion dollars in 2011 (Berwick & Hackbarth, 2012).  There has been increased emphasis on overtesting, such as requesting costly imaging scans when they may not be medically necessary (Carpenter, Raja & Brown, 2015). 

Diagnostic error is by no means the sole cause of medical incidents. There are a number of factors tied to the wider work environment, culture and technology that can contribute to incidents and errors. A lot of these factors are challenging to isolate and emulate in an experimental setting. One could intuit however that an error in diagnosis can have knock-on effects later on in the medical timeline. A misdiagnosis increases the likelihood of inappropriate treatment, which in turn increases the likelihood of an adverse patient event. Gaining a greater understanding of the causes of diagnostic error can have important implications for future interventions within healthcare settings. 

One account of diagnostic error is that they can stem from cognitive biases during decision making. Frotvedt et al (2020) looked at primacy (information presented earlier being more influential on judgements than information presented later) and congruence (preferentially seeking information to confirm prior beliefs) biases in mental health diagnoses. Chapman, Bergus & Elstein (1996) found a recency effect (rather than a primacy effect) when presenting physicians with a patient history either at the beginning or end of a patient vignette. Another set of diagnostic pitfalls has been found for physicians when making probability judgements. Arkes, Aberegg and Arpin (2022) showed that a majority of physicians incorrectly estimate the joint probability of two medical outcomes given each of their independent probabilities. Redelmeier and Shafir (2023) found when medical professionals estimated the probability that patient was infected with COVID, their estimates were affected by a test results for an alternative diagnosis even when a patient could have multiple conditions (e.g. both COVID and influenza), especially when the conditions are similar in nature.

Making a diagnosis involves considering a hypothesis as likely because the displayed symptoms seem to correspond with a prototypical case of a particular condition (despite symptoms being presented to the contrary). A clinician may have recently experienced a patient with a particular condition and, upon seeing another patient with what are perceived to be similar symptoms, is then more likely to choose the same diagnosis again. While it seems intuitive that classical decision making biases affect those in healthcare too (Restrepo et al, 2020), the empirical evidence is scant, particularly when showing that these biases contribute to medical errors (van den Berge & Mamede, 2013). One example that attempted to automatically detect uses of heuristics and biases by dermatologists, examples of satisficing bias (premature closure) and anchoring were found, but very few examples of other biases such as availability and representative were found (Crowley et al, 2012). Results of anchoring bias in clinical errors could be driven by a failure to adjust sufficiently based on a self-generated anchor (Epley & Gilovich, 2006) and that the anchoring effect size is affected by the order of information such that information presented later is less influential on decisions (Ellis et al, 1990). This corresponds with work that explains primacy biases as a result of an attentional decrement for successive items of information (Cunnington et al, 1997), which we can investigate as a factor that contributes to premature closure and overconfidence in information seeking. Attempts to lower the likelihood of diagnostic error has involved the use of checklists as cognitive aids (Ely, Graber & Croskerry, 2011, Kämmer et al, 2021) in order to ensure that diagnoses are not missed from the doctor’s thought process. 

Overall, we can infer that the relationship between confidence and information seeking could have wide-reaching consequences within healthcare. In other words, seeking too much information can lead to unnecessary wastage of time and resources within the healthcare system, whilst too little information can lead to overcommitting to certain diagnoses too early, increasing the likelihood of diagnostic error.

## Confidence and its Miscalibrations {.unnumbered}

At this point, we shall revisit the scenario presented in the Preface section. In summary, a patient is presenting with a set of symptoms that requires doctors to assign a diagnosis in order to guide future treatment. As part of the deliberation around the diagnosis, one of the doctors presents their opinion that the patient has suffered a pneumothorax. When presenting this opinion, they do so with a high level of confidence, meaning that they describe themselves as being nearly certain that their assessment of the patient is the correct one. Due to their high confidence, this doctor’s opinion is difficult for others to disagree with. Confident individuals also tend to be more influential on others in a group (Zarnoth & Sniezek, 1997) and can even causally increase the confidence of other observers when faced with high confidence decision makers (Cheng et al, 2021).  As we shall explore, confidence is commonly useful as a predictor of another person’s accuracy, especially when feedback is not readily available of the true accuracy of the individual. This behaviour has been observed in mock jury trials in which participants hear eyewitness testimonies presented with high confidence and then perceived as more credible than testimonies provided with low confidence (Cutler, Penrod & Dexter, 1989, Roediger, Wixted & DeSoto, 2012). There may be a tacit assumption that others will be metacognitive aware and calibrate their confidence with their true accuracy, meaning that heeding high confidence advice or judgements would be an optimal strategy for maximising accuracy. However, this can be a serious issue when high confidence errors lead others astray. Highly confident members within a group could also unknowingly reduce the chance of less confident members speaking up about potential errors, which is a problem within healthcare (Hémon et al, 2020). 

Confidence can be considered to be an individual’s internal probability of a given decision being correct when taking into account the evidence used to make that decision (Fleming & Daw, 2017). Confidence has been proposed as a conscious, introspective property given that it is used in communication with others (Shea et al, 2014). This becomes an especially important point when making group decisions and aligning mental models between members of the group. Confidence also varies across individuals with what may be considered a ‘subjective fingerprint’ (Ais et al, 2016), such as if individuals are systematically underconfident or overconfident. Confident individuals also tend to be more influential on others in a group (Zarnoth & Sniezek, 1997) and can even causally increase the confidence of other observers when faced with high confidence decision makers (Cheng et al, 2021).

Confidence has a number of interesting facets that sheds some light on its cognitive mechanisms. It increases in the face of a larger amount of evidence overall, even if some evidence favours decision alternatives other than the one chosen (Ko, Feurnigel et al, 2022). Confidence also has a relation to decision times, as it increases with viewing time of a stimulus irrespective of decision accuracy (Raush, Hellmann & Zehetteitner, 2018). A faster response time is associated with higher confidence (Audley, 1960), which is a heuristic used not only for an individual introspecting about their own decision but also by observers who are attempting to infer the confidence of others (Patel et al, 2012). Confidence may also be used to predict choosing tasks to perform where the tasks have differing levels of effort involved (Carlebach & Yeung, 2020), with task choice being induced by using extra evidence to boost confidence (Kool et al, 2010) which corresponds with the aforementioned finding that a larger quantity of evidence leads to higher confidence. Confidence has been explained computationally as the difference in the strength of evidence for a decision alternative compared to other alternatives (Vickers & Packer, 1982). After a decision is made, we continue to process evidence, meaning that we continue to think about a decision after the decision is made. This means that having ‘second thoughts’ or changes of mind are more likely with a lower level of initial confidence (and hence a lower strength of evidence). Confidence has been thought to tie into the global workspace model of consciousness, whereby confidence is broadcast for other systems (e.g memory, perception, attention) to utilise (Dehaene & Changeaux, 2011). The case for confidence as a conscious introspective property is bolstered when considering its evolutionary origins as a communication tool with other people, especially for group decisions (Shea, 2014). 

One is said to be well-calibrated with regards to their confidence if their internal likelihood of being correct is predictive of their true accuracy. However, a number of factors may distort subjective confidence such that confidence becomes decoupled from the true accuracy of one’s decisions. This decoupling is known as ‘miscalibration’. One would show miscalibration of confidence if they were confident when incorrect or uncertain when they are correct. These two cases can be referred to as overconfidence and underconfidence respectively. Miscalibration of confidence is part of a wider corpus of work on deficiencies in self-monitoring, with individuals being far more likely to notice their own execution errors (slips) than their own method errors (mistakes) (Allwood, 1984). These latter errors are where overconfidence can arise from. 

Katz (1984) proposed that doctors do not approach uncertainty in the practice of medicine in the same way that they do in theory. This was illustrated in an example where a doctor was keenly aware of the lack of medical consensus (at the time of writing) on the best course of treatment for breast cancer, but the same doctor was highly confident when recommending surgery to the patient. Evidence for overconfidence has been shown in other clinical contexts too. In a task that involved diagnosing ultrasound scans, it was found that overconfidence was negatively correlated with the amount of clinical experience that the clinicians/participants had (Schoenherr, Waechter & Millington, 2018). However, it has also been found that underconfidence can be more prevalent than overconfidence, especially when comparing medical students to residents (Friedman et al, 2005). Similarly, Yang and Thompson (2010) had 103 nursing students and 34 experienced nurses work through risk assessment vignettes and provide confidence judgements. They found that experienced nurses exhibited similar performance to nursing students, but were more confident in their judgements, showing differences in confidence calibration across experience levels. More broadly, highly confident members within a group could unknowingly reduce the chance of less confident members speaking up about potential errors, which is a problem within healthcare (Hémon et al, 2020). Overconfidence has also been linked to a lower likelihood of sufficient patient management and clinical effort as per a field study in Senegal (Kovacs, Lagarde & Cairns, 2019).

## Linking Confidence and Information Seeking {.unnumbered}

Medical decisions have been thought of as ‘ideal’ when using the hypothetico-deductive process (Kuipers & Kassirer, 1984), whereby hypotheses are formulated based on specific features of a patient and are then linked to established criteria for a diagnosis, with further information gathering to test these hypotheses (Higgs et al, 2008). However, this process being a standard to strive for has been argued to increase the risk of confirmation bias by collecting data to fit pre-existing theories rather than crafting theories around collected data (Chi, Glaser & Farr, 2014). 

The link between confidence and information seeking has been previously investigated in cognitive psychology research. Desender, Boldt & Yeung (2018) manipulated the variance of a visual stimulus and found that higher variability was associated with lower confidence and higher information seeking. Information can be gathered that is either in support of or against an individual’s beliefs or decisions, with information being used to accumulate strength of evidence in favour of different decision alternatives (Vickers & Packer, 1982). However, the mere quantity of information, even if that information favours the non-preferred option, may increase confidence in of itself (Ko, Feuerriegel, et al, 2022). Choosing when to stop gathering information has been found to produce a ‘boost’ in confidence, though this is not the case when participants are forced to stop gathering information at a time point that they do not choose themselves (Wei, 2022). 

One of the earliest papers to find evidence of overconfidence and information seeking in clinical settings was by Oskamp (1965). This study focused on clinical psychology and tasked participants with answering questions about a patient who may have been displaying signs of post-traumatic stress disorder. After receiving each set of new information, participants could revise their answers to all questions and report their new confidence. Oskamp found that with each new set of information, participants increased their confidence but did not significantly improve their accuracy. In fact, participants were less likely to change their answers as more information was provided. This showed that confidence could be linked to mere receipt of information and that participants were more confident than they should have been. In a sample of 118 physicians presented with patient vignettes, it was found that higher confidence, as well as a higher difficulty, was associated with a decreased amount of diagnostic tests (Meyer et al, 2013). It has also been observed previously that physicians may ‘distort’ neutral or inconclusive evidence to be interpreted as supporting prior beliefs (Kostopolou et al, 2012). Similarly, it has been found that a patient’s case history that suggests a particular diagnosis prompts selective processing of clinical features that favour the initial diagnosis (Leblanc, Brooks & Norman, 2022).

The relationship between confidence and information seeking is yet to be determined in the context of diagnosis. Hence, one aim is to investigate at information seeking in diagnostic decision making to look at differences in calibrations of confidence. 

## Expertise {.unnumbered}

One of the primary implications and practical applications of this research is to inform the training of medical students and novice medical professionals, especially in their communication of confidence and information gathering strategies with making diagnostic decisions. We must therefore look at the differences between novices and experts more broadly and then focus on novices and experts within healthcare specifically.

The differences between experts and novices were explored in the seminal work of Kruger and Dunning (1999). This paper looked at how individuals are aware of their own accuracy, which has been mentioned previously as being called metacognition. What the authors showed was a clear relationship between one’s ability and awareness of their own ability. When participants were better at a task (test of humour, grammar and logic), they accurately estimated their own percentile rank amongst the other participants. Participants who performed worse (especially those placed in the bottom quartile) severely overestimated their own accuracy. This finding has been highly influential in researching the differences between experts’ and novices’ metacognitive abilities. This relationship has been similarly explored in osteopathic medical students asked to classify heart arrhythmias, though the effect was found to be curvilinear such that metacognition was best for participants in the range of 70-85% accuracy (Mann, 1993). While Kurger and Dunning had famously proclaimed that individuals can be ‘unskilled and unaware of it’, this work from Mann provided evidence for individuals who could also be ‘skilled and unaware of it’. The relationship between confidence, accuracy and expertise/experience should hence be explored further in clinicians. 

Expertise can be thought of as the progression from a superficial understanding of problems and an effortful problem solving procedure to a principled understanding made evident by automatic pattern recognition (Hoffman, 1998). The nature of expertise is difficult to pin down, namely because it is hard to capture in a meaningful way. A potential indicator could be the length of time that an individual has had experience with a task. However, one’s competence at the task likely does not increase monotonically over time and this function may differ from person to person. This is where one might consider that there is some latent trait variable of ‘natural aptitude’ that affects the change in competence over time. In other words, those who are more ‘naturally gifted’ at a task may improve more quickly than others over time. However, it is unclear how this latent variable can factor into any given task. For instance, are some people better than others at perceptual tasks? It is difficult to imagine one to be an expert at perception. Hence, expertise may only make sense for tasks where learning is involved, as there is an expected change in competence over time. One could test domain knowledge as a means of testing expertise, but this prompts questions in situations when domain knowledge does not consistently correspond with task competence. Accounts of expertise also do not explain why experts may still differ in their decisions or judgements despite fairly similar levels of experience or domain knowledge. 

Medical students have a large body of knowledge to absorb as part of their education. Part of their job with regards to diagnosing patients is to identify patterns in the presented symptoms and match them to the most likely condition that would cause these symptoms. As these students gain more practical experience and see more patients, they obviously become adept at this task. Experts are able to recall information more automatically, as well as having a better organised and integrated knowledge base (Persky & Robinson, 2017). More experienced clinicians also have a higher confidence in medical skills (e.g. administration of intravenous drugs, preparation of equipment for intubation, packed red blood cell transfusion) which correlates with the number of times they report performing these skills (Morgan & Cleave-Hogg, 2002). These findings in themselves are not surprising. However, looking at the differences in confidence and strategies around information seeking that novices and experts use could be useful for understanding what expertise actually means in healthcare. This is especially significant given that perceptions vary greatly between individuals in terms of what expertise actually entails, both among novices and experts (St Pierre & Nyce, 2020). Understanding how expertise translates into the use of information to reduce uncertainty and increase confidence can hence inform the training of newer medical students.

Experts realise that they can, or even are forced to, utilise either mental or organisational shortcuts when caring for a patient. When asked to interpret an electrocardiogram (a recording of electrical activity in the heart, ECG) and give a diagnosis for any abnormalities in the patient’s heartbeat, Wood et al (2014) found that experts were quicker and more confident in the task than novices. In addition though, eye gaze data found that experts were quicker in identifying the critical points of interest in the ECG trace. This indicated that experts had more codified strategies for focusing on the most important pieces of visual information. This is backed up by Carrigan et al (2019), who found that expert radiologists were more sensitive to informative visual features of a chest radiograph (ie a lung nodule) that naïve observers did not view as salient. Experts are seemingly able to make inferences of high relevance more easily, which is distinct from their recall ability (Patel & Medley-Mark, 1986). There is also evidence that experts’ confidence was sensitive to the consistency of information provided. Tabak, Bar-Tal and Cohen-Mansfield (1996) provided two patient scenarios to experienced nurses and nursing students, with one scenario presenting information about the patient fully consistent with a provided diagnosis and the other containing some information inconsistent with the provided diagnosis. The nurses reported lower confidence and higher subjective difficulty in the case of the inconsistent scenario, whilst the students showed little difference in both measures across the two scenarios. Brannon and Carson (2003) used scenarios adapted from Tabak, Bar-Tal and Cohen-Mansfield (1996) and found a similar effect for confidence across a larger sample size of nurses and nursing students. When considering classical works from psychology, the key properties of expert performance can be summarised as superior pattern recognition (Chase & Simon, 1973) and better forward reasoning from established facts (Larkin, McDermott, Simon & Simon, 1980). In the same way that confidence can lead to a higher influence in group decisions (Zarnoth & Sniezek, 1997), expertise may in itself have a high influence within a group decision. Salem-Schatz, Avorn and Soumerai (1990) found that 61% of surveyed resident doctors had ordered unnecessary transfusions at least once a month due to a suggestion to do so by a more senior physician.

Hence, studying the effects of clinical experience on diagnostic decision making is of interest when it comes to understanding implications for medical education and the relationship between confidence and information seeking may change as doctors become more experienced.


